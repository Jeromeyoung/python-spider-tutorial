# 爬虫学习笔记（疫情数据可视化）

## 1. 项目展示



![image-20200813092800649](images\image-20200813092800649.png)

![image-20200813092907589](images\image-20200813092907589.png)

![image-20200813092928468](images\image-20200813092928468.png)

![image-20200813093042187](images\image-20200813093042187.png)



![image-20200813093223699](images\image-20200813093223699.png)



## 2. 前置技能

- 熟悉python基本语法
- 了解html网页框架
- 了解json格式



## 3. 技术亮点

1. 采用requests 库爬取数据；
2.  采用BS4解析页面数据；
3. 采用正则表达式提取不规则数据；
4. 采用json模块处理json数据；
5. 采用类封装爬虫项目；
6. 对爬虫代码进行重构，提供其可扩展性和复用性；



## 4. 开发环境

### 1. 采用框架

- python
- requests
- beautifulsoups4
- lxml

### 2. 开发工具

- pycharm 2020



## 5. requests 库

### 5.1 requests 库介绍与安装

- 什么requests？

> requests库是一个模仿浏览器客户端向服务器发送网页请求的第三方python库；

- requests 安装

```cmd
# requests 镜像安装
pip install requests -i https://mirrors.aliyun.com/pypi/simples
```



### 5.2 requests 库基本使用

```
# 导入库
import requests

# 发送情况，获取响应
url = https://xxx.com
response = requests.get(url)

# 获取响应数据
response.encoding = 'utf-8'
print(response.content)
print(response.text)
print(response.content.decode('utf-8'))
```



### 5.3 response 基本属性

- response.text：响应体字符类型
- response.encoding = 'utf-8' ：指定响应体的编码方式为utf-8
- response.content：响应体二进制原始流类型
- response.content.decode('utf-8')

```cmd
# 将二进制流转换为字符串，并打印输出
print(response.content.decode('utf-8'))

# 指定响应体编码方式为utf-8，然后打印输出响应体字符类数据
response.coding = 'utf-8'
print(response.text)
```

### 5.4 requests 请求实例

```cmd
# 导入第三方模块
import requests

# 发送get请求，获取响应体
url = 'https://www.baidu.com'
response = request.get(url)

# 获取响应体文本内容
text = response.content.encode('utf-8')
print(text)

# 或使用以下方法
# response.encoding = 'utf-8'
# text = response.text

```





## 6. BeautifulSoup 库

### 6.1 BeautifulSoup库介绍与安装

- 什么是 BeautifulSoup 

> BeautifulSoup 是一个可以从html 或 xml中提取数据的第三方库。

- BeautifulSoup 库安装

```cmd
# 安装 bs4
pip install bs4

# 安装 lxml
pip instal lxml
```

### 6.2 BeautifulSoup 基本使用

```cmd
# 导入模块
from bs4 import BeautifulSoup4

# 指定解析器进行html文档的解析
soup = BeautifulSoup('<html>data</html>', 'lxml')
print(soup.prettify())
```

### 6.3 BeautifulSoup对象“find()方法”和“Tag标签”

#### （1）find()方法

> find()函数的作用，就是帮我从html文档对象中提取你想要的“某个标签”内容，生成一个”Tag对象”。具体查询的条件有以下三种方式：
>
> - 通过“标签名”查找某个标签，并提取此标签所有内容
> - 通过“属性“查找某个标签，并提取此标签所有内容；
> - 通过“内容”匹配查找某个标签，并提取此标签所有内容；

- 标签名查找

```cmd
tag_a = soup.find('a')
```

- 属性查找

```cmd
attr = soup.find(id='link1') 
或
attr = soup.find(attrs={'id':'link1'})
```

- 内容查找

```cmd
text = soup.find(text='Elise')
```

- 所有内容查找

```cmd
tags_a = soup.findall('a')
```



#### （2）Tag标签

- 什么是Tag对象？

  >  我们可以直接打印下以上标签`a`的类型，就可以看到其就是Tag类型。

  ```cmd
  a = soup.find('a')
  print(type(a))
  
  # 打印输出结果如下
  <class 'bs4.element.Tag'>
  ```

- Tag对象的属性

  > Tag 有以下三种属性值，通过响应的属性值，我们可以直接提取Tag标签内部的内容。

  - a.name
  - a.attrs
  - a.text

  ```cmd
  tag = soup.find('title')
  print(tag.name)
  print(tag.attrs)
  print(tag.text)
  ```

  

### 6.4 提取疫情数据

```cmd
# 1. 导入相关模块

#

```



## 7. 正则表达式

### 7.1 正则表达式的基本概念

- 什么是正则表达式
- 常见语法
- re.findall()
- r原始字符串匹配d